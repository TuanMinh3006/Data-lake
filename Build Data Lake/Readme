###Cài đặt Hadoop
Bước 1: Cài đặt SSH
sudo apt install ssh
Bước 2: Cài đặt PDSH
sudo apt install pdsh
Bước 3:
Mở tệp .bashrc  bằng lệnh sau:
Nano .bashrc
Thêm vào cuối tệp dòng sau: export PDSH_RCMD_TYPE=ssh
 
Bước 4: Bây giờ hãy cấu hình SSH. Hãy tạo một khóa mới bằng lệnh sau:
ssh-keygen -t rsa -P ""
 
Bước 5: Bây giờ chúng ta cần sao chép khóa chung vào tệp authorized_keys bằng lệnh sau:
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
 
Bước 6: Bây giờ chúng ta có thể xác minh cấu hình SSH bằng cách kết nối với localhost:
ssh localhost
 
Bước 7: Cài đặt Java 8 với lệnh sau
sudo apt install openjdk-8-jdk
 
kiểm tra xem Java hiện đã được cài đặt đúng chưa:
 
Bước 8: Tải xuống Hadoop bằng lệnh sau:
Sudo wget -P~ https://dlcdn.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz
 
Bước 9: Giải nén tệp hadoop-3.4.0.tar.gz
tar xzf Hadoop-3.4.0.tar.gz
Bước 10: Đổi tên thư mục  hadoop-3.4.0 thành Hadoop
mv hadoop-3.4.0 hadoop
Bước 11: Mở tệp hadoop-env.sh trong trình chỉnh sửa nano để chỉnh sửa JAVA_HOME:
nano ~/hadoop/etc/hadoop/hadoop-env.sh
Dán dòng này vào JAVA_HOME:
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
 
Bước 12: Thay đổi thư mục thư mục hadoop thành /usr/local/hadoop. Đây là lệnh:
sudo mv hadoop /usr/local/hadoop
 
Bước 13: Mở tệp environment bằng nano
sudo nano /etc/environment
Thêm các cấu hình sau:
PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/hadoop/bin:/usr/local/hadoop/sbin"
JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64/jre"
 
Bước 14: Thêm một người dùng có tên là hadoopuser và thiết lập cấu hình cho nó:
sudo adduser hadoopuser
Cung cấp mật khẩu và có thể để trống phần còn lại, chỉ cần nhấn Enter.
 
Bây giờ hãy gõ các lệnh sau:
sudo usermod -aG hadoopuser hadoopuser
sudo chown hadoopuser:root -R /usr/local/hadoop/
sudo chmod g+rwx -R /usr/local/hadoop/
sudo adduser hadoopuser sudo
Bước 15: Mở tệp máy chủ và chèn cấu hình Mạng:
sudo nano /etc/hosts
 
Bước 16: Bây giờ là lúc tạo Slave. Tắt Máy ảo chính của bạn và sao chép nó hai lần, đặt tên cho một Slave1 và Slave2 khác.
 
 
 
Làm tương tự với slave2
Cấu hình ip cho các máy
 
 
 

Bước 17: Trên máy master, mở tệp hostname bằng nano
sudo nano /etc/hostname
 
Bây giờ làm tương tự với slave1 và slave2
 
 
Ngoài ra, bạn nên khởi động lại tất cả máy để cấu hình này có hiệu lực:
Sudo reboot
Bước 18: Cấu hình SSH trên hadoop-master, với hadoopuser. Đây là lệnh:
su - hadoopuser
 
Bước 19: Tạo khóa SSh
ssh-keygen -t rsa
 
Bước 20: Sao chép khóa SSH cho tất cả người dùng. Sử dụng lệnh này:
ssh-copy-id hadoopuser@hadoop-master
ssh-copy-id hadoopuser@hadoop-slave1
ssh-copy-id hadoopuser@hadoop-slave2
 
 
 
Bước 21: Trên hadoop-master, mở file core-site.xml trên nano:
sudo nano /usr/local/hadoop/etc/hadoop/core-site.xml
Sau đó thêm các cấu hình sau:
<configuration>
<property>
<name>fs.defaultFS</name>
<value>hdfs://hadoop-master:9000</value>
</property>
</configuration>
 
Bước 22: Vẫn trên hadoop-master, mở tệp hdfs-site.xml.
sudo nano /usr/local/hadoop/etc/hadoop/hdfs-site.xml
Thêm các cấu hình sau:
<configuration>
<property>
<name>dfs.namenode.name.dir</name><value>/usr/local/hadoop/data/nameNode</value>
</property>
<property>
<name>dfs.datanode.data.dir</name><value>/usr/local/hadoop/data/dataNode</value>
</property>
<property>
<name>dfs.replication</name>
<value>2</value>
</property>
</configuration>
 
Bước 23: Chúng ta vẫn đang sử dụng hadoop-master, hãy mở tệp workers
sudo nano /usr/local/hadoop/etc/hadoop/workers
Thêm hai dòng sau:
hadoop-slave1
hadoop-slave2
 
Bước 24: Chúng ta cần sao chép cấu hình Hadoop Master sang các máy phụ, để thực hiện điều đó, chúng ta sử dụng các lệnh sau:
Scp /usr/local/hadoop/etc/hadoop/* hadoop-slave1:/usr/local/hadoop/etc/hadoop/
scp /usr/local/hadoop/etc/hadoop/* hadoop-slave2:/usr/local/hadoop/etc/hadoop/
 
 
Bước 25: Bây giờ chúng ta cần định dạng hệ thống tệp HDFS. Chạy các lệnh này:
source/etc/environment
hdfs namenode -format
 
Bước 26: Bắt đầu HDFS bằng lệnh này:
 
Để kiểm tra xem điều này có hiệu quả hay không, hãy chạy lệnh “jps”. Điều này sẽ cho bạn biết những tài nguyên nào đã được khởi tạo.
Kiểm tra tương tự với slaves
 
 
Bước 26: Mở trình duyệt của bạn và gõ hadoop-master:9870
 
 
Bước 27: Để cấu hình yarn, chỉ cần thực hiện các lệnh sau:
export HADOOP_HOME="/usr/local/hadoop"
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
 
Bước 28:
Ở cả 2 máy slaves, mở yarn-site.sml bằng nano
sudo nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
Thêm các cấu hình sau trên cả 2 máy slaves
<property>
<name>yarn.resourcemanager.hostname</name>
<value>hadoop-master</value>
</property>

 
 
Bước 29:
Trên máy master, hãy bắt đầu yarn. Sử dụng lệnh này:
start-yarn.sh
Mở trình duyệt và gõ http://hadoop-master:8088/cluster
 
 
Cài đặt Nifi
Bước 1: Cài đặt Java 11
sudo apt install openjdk-11-jdk
 
Bước 2: Cài đặt Apache Nifi
wget https://dlcdn.apache.org/nifi/1.25.0/nifi-1.25.0-bin.zip
 
Bước 3: Giải nén gói nifi-1.25.0-bin.zip
Bước 4: Đặt đường dẫn JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/
 
Bước 5: Bắt đầu Apache nifi
Sau đó, đi tới thư mục Nifi bin và khởi động Máy chủ bằng cách sử dụng lệnh start ./nifi.sh như được đề cập bên dưới.
 
Bây giờ bạn có thể truy cập Trình duyệt của mình và mở https://127.0.0.1:8443/nifi/
 

